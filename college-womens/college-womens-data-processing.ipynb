{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url, delay=1, headers=None, proxy=None):\n",
    "    \"\"\"\n",
    "    Fetches and parses a webpage with BeautifulSoup, handling 403 errors\n",
    "    by setting headers, delays, and optional proxies.\n",
    "\n",
    "    Parameters:\n",
    "        url (str): The URL of the webpage to scrape.\n",
    "        delay (int): The delay (in seconds) between requests. Default is 1 second.\n",
    "        headers (dict): Optional headers to include in the request.\n",
    "        proxy (dict): Optional dictionary for proxies.\n",
    "\n",
    "    Returns:\n",
    "        BeautifulSoup object of the parsed page or None if request fails.\n",
    "    \"\"\"\n",
    "\n",
    "    # Default headers to mimic a browser request if none are provided\n",
    "    if headers is None:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        # Send the request with headers and optional proxy\n",
    "        response = requests.get(url, headers=headers, proxies=proxy)\n",
    "        \n",
    "        # Check for 403 Forbidden error\n",
    "        if response.status_code == 403:\n",
    "            print(\"403 Forbidden: Access to the page is restricted.\")\n",
    "            return None\n",
    "        \n",
    "        # Add delay to avoid rapid requests\n",
    "        time.sleep(delay)\n",
    "\n",
    "        # Parse the content with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        return soup\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_list(url):\n",
    "    try:\n",
    "        # Set headers to mimic a browser request\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the list within the specified section and div\n",
    "        standings_div = soup.find('div', class_='standings')\n",
    "        if standings_div:\n",
    "            list_items = standings_div.find_all('li')\n",
    "            standings = [item.text.strip() for item in list_items if item.text.strip()]\n",
    "            return standings\n",
    "        else:\n",
    "            print(f\"No standings found for {url}\")\n",
    "            return None\n",
    "\n",
    "    except requests.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred while scraping {url}: {http_err}\")\n",
    "        return None\n",
    "    except requests.RequestException as req_err:\n",
    "        print(f\"Request error occurred while scraping {url}: {req_err}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while scraping {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_multiple_urls(urls):\n",
    "#     # Dictionary to store the results for each URL\n",
    "#     results = {}\n",
    "#     for url in urls:\n",
    "#         print(f\"Scraping data from {url}...\")\n",
    "#         data = scrape_list(url)\n",
    "#         results[url] = data if data else \"No data found\"\n",
    "#     return results\n",
    "\n",
    "def scrape_multiple_urls_dict(urls):\n",
    "    # Dictionary to store the results for each year\n",
    "    results = {}\n",
    "    for year, url in urls.items():\n",
    "        print(f\"Scraping data for the year {year} from {url}...\")\n",
    "        data = scrape_list(url)\n",
    "        results[year] = data if data else \"No data found\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    1987: 'https://collegechampionships.usaultimate.org/d1-women/history/1987-d-i-women/',\n",
    "    1988: 'https://collegechampionships.usaultimate.org/d1-women/history/1988-d-i-women/',\n",
    "    1989: 'https://collegechampionships.usaultimate.org/d1-women/history/1989-d-i-women/',\n",
    "    1990: 'https://collegechampionships.usaultimate.org/d1-women/history/1990-d-i-women/',\n",
    "    1991: 'https://collegechampionships.usaultimate.org/d1-women/history/1991-d-i-women/',\n",
    "    1992: 'https://collegechampionships.usaultimate.org/d1-women/history/1992-d-i-women/',\n",
    "    1993: 'https://collegechampionships.usaultimate.org/d1-women/history/1993-d-i-women/',\n",
    "    1994: 'https://collegechampionships.usaultimate.org/d1-women/history/1994-d-i-women/',\n",
    "    1995: 'https://collegechampionships.usaultimate.org/d1-women/history/1995-d-i-women/',\n",
    "    1996: 'https://collegechampionships.usaultimate.org/d1-women/history/1996-d-i-women/',\n",
    "    1997: 'https://collegechampionships.usaultimate.org/d1-women/history/1997-d-i-women/',\n",
    "    1998: 'https://collegechampionships.usaultimate.org/d1-women/history/1998-d-i-women/',\n",
    "    1999: 'https://collegechampionships.usaultimate.org/d1-women/history/1999-d-i-women/',\n",
    "    2000: 'https://collegechampionships.usaultimate.org/d1-women/history/2000-d-i-women/',\n",
    "    2001: 'https://collegechampionships.usaultimate.org/d1-women/history/2001-d-i-women/',\n",
    "    2002: 'https://collegechampionships.usaultimate.org/d1-women/history/2002-d-i-women/',\n",
    "    2003: 'https://collegechampionships.usaultimate.org/d1-women/history/2003-d-i-women/',\n",
    "    2004: 'https://collegechampionships.usaultimate.org/d1-women/history/2004-d-i-women/',\n",
    "    2005: 'https://collegechampionships.usaultimate.org/d1-women/history/2005-d-i-women/',\n",
    "    2006: 'https://collegechampionships.usaultimate.org/d1-women/history/2006-d-i-women/',\n",
    "    2007: 'https://collegechampionships.usaultimate.org/d1-women/history/2007-d-i-women/',\n",
    "    2008: 'https://collegechampionships.usaultimate.org/d1-women/history/2008-d-i-women/',\n",
    "    2009: 'https://collegechampionships.usaultimate.org/d1-women/history/2009-d-i-women/',\n",
    "    2010: 'https://collegechampionships.usaultimate.org/d1-women/history/2010-d-i-women/',\n",
    "    2011: 'https://collegechampionships.usaultimate.org/d1-women/history/2011-d-i-college-womens/',\n",
    "    2012: 'https://collegechampionships.usaultimate.org/d1-women/history/2012-d-i-college-womens/',\n",
    "    2013: 'https://collegechampionships.usaultimate.org/d1-women/history/2013-d-i-college-womens/',\n",
    "    2014: 'https://collegechampionships.usaultimate.org/d1-women/history/2014-d-i-college-womens/',\n",
    "    2015: 'https://collegechampionships.usaultimate.org/d1-women/history/2015-d-i-women/',\n",
    "    2016: 'https://collegechampionships.usaultimate.org/d1-women/history/2016-d-i-college-womens/',\n",
    "    2017: 'https://collegechampionships.usaultimate.org/d1-women/history/2017-d-i-women/',\n",
    "    2018: 'https://collegechampionships.usaultimate.org/d1-women/history/2018-d-i-women/',\n",
    "    2019: 'https://collegechampionships.usaultimate.org/d1-women/history/2019-d-i-women/',\n",
    "    # 2020 no season\n",
    "    2021: 'https://collegechampionships.usaultimate.org/d1-women/history/2019-d-i-women-2/',\n",
    "    2022: 'https://collegechampionships.usaultimate.org/d1-women/history/2019-d-i-women-2-2/',\n",
    "    2023: 'https://collegechampionships.usaultimate.org/d1-women/history/2019-d-i-women-2-2-2/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for the year 1987 from https://collegechampionships.usaultimate.org/d1-women/history/1987-d-i-women/...\n",
      "Scraping data for the year 1988 from https://collegechampionships.usaultimate.org/d1-women/history/1988-d-i-women/...\n",
      "Scraping data for the year 1989 from https://collegechampionships.usaultimate.org/d1-women/history/1989-d-i-women/...\n",
      "Scraping data for the year 1990 from https://collegechampionships.usaultimate.org/d1-women/history/1990-d-i-women/...\n",
      "Scraping data for the year 1991 from https://collegechampionships.usaultimate.org/d1-women/history/1991-d-i-women/...\n",
      "Scraping data for the year 1992 from https://collegechampionships.usaultimate.org/d1-women/history/1992-d-i-women/...\n",
      "Scraping data for the year 1993 from https://collegechampionships.usaultimate.org/d1-women/history/1993-d-i-women/...\n",
      "Scraping data for the year 1994 from https://collegechampionships.usaultimate.org/d1-women/history/1994-d-i-women/...\n",
      "Scraping data for the year 1995 from https://collegechampionships.usaultimate.org/d1-women/history/1995-d-i-women/...\n",
      "Scraping data for the year 1996 from https://collegechampionships.usaultimate.org/d1-women/history/1996-d-i-women/...\n",
      "Scraping data for the year 1997 from https://collegechampionships.usaultimate.org/d1-women/history/1997-d-i-women/...\n",
      "Scraping data for the year 1998 from https://collegechampionships.usaultimate.org/d1-women/history/1998-d-i-women/...\n",
      "Scraping data for the year 1999 from https://collegechampionships.usaultimate.org/d1-women/history/1999-d-i-women/...\n",
      "Scraping data for the year 2000 from https://collegechampionships.usaultimate.org/d1-women/history/2000-d-i-women/...\n",
      "Scraping data for the year 2001 from https://collegechampionships.usaultimate.org/d1-women/history/2001-d-i-women/...\n",
      "Scraping data for the year 2002 from https://collegechampionships.usaultimate.org/d1-women/history/2002-d-i-women/...\n",
      "Scraping data for the year 2003 from https://collegechampionships.usaultimate.org/d1-women/history/2003-d-i-women/...\n",
      "Scraping data for the year 2004 from https://collegechampionships.usaultimate.org/d1-women/history/2004-d-i-women/...\n",
      "Scraping data for the year 2005 from https://collegechampionships.usaultimate.org/d1-women/history/2005-d-i-women/...\n",
      "Scraping data for the year 2006 from https://collegechampionships.usaultimate.org/d1-women/history/2006-d-i-women/...\n",
      "Scraping data for the year 2007 from https://collegechampionships.usaultimate.org/d1-women/history/2007-d-i-women/...\n",
      "Scraping data for the year 2008 from https://collegechampionships.usaultimate.org/d1-women/history/2008-d-i-women/...\n",
      "Scraping data for the year 2009 from https://collegechampionships.usaultimate.org/d1-women/history/2009-d-i-women/...\n",
      "Scraping data for the year 2010 from https://collegechampionships.usaultimate.org/d1-women/history/2010-d-i-women/...\n",
      "Scraping data for the year 2011 from https://collegechampionships.usaultimate.org/d1-women/history/2011-d-i-college-womens/...\n",
      "Scraping data for the year 2012 from https://collegechampionships.usaultimate.org/d1-women/history/2012-d-i-college-womens/...\n",
      "Scraping data for the year 2013 from https://collegechampionships.usaultimate.org/d1-women/history/2013-d-i-college-womens/...\n",
      "Scraping data for the year 2014 from https://collegechampionships.usaultimate.org/d1-women/history/2014-d-i-college-womens/...\n",
      "Scraping data for the year 2015 from https://collegechampionships.usaultimate.org/d1-women/history/2015-d-i-women/...\n",
      "Scraping data for the year 2016 from https://collegechampionships.usaultimate.org/d1-women/history/2016-d-i-college-womens/...\n",
      "Scraping data for the year 2017 from https://collegechampionships.usaultimate.org/d1-women/history/2017-d-i-women/...\n",
      "Scraping data for the year 2018 from https://collegechampionships.usaultimate.org/d1-women/history/2018-d-i-women/...\n",
      "Scraping data for the year 2019 from https://collegechampionships.usaultimate.org/d1-women/history/2019-d-i-women/...\n",
      "Scraping data for the year 2021 from https://collegechampionships.usaultimate.org/d1-women/history/2019-d-i-women-2/...\n",
      "Scraping data for the year 2022 from https://collegechampionships.usaultimate.org/d1-women/history/2019-d-i-women-2-2/...\n",
      "Scraping data for the year 2023 from https://collegechampionships.usaultimate.org/d1-women/history/2019-d-i-women-2-2-2/...\n"
     ]
    }
   ],
   "source": [
    "all_standings = scrape_multiple_urls_dict(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standings for 1987:\n",
      "['1-Kansas', '2-California- Davis', '3-Humboldt State', '4-Massachusetts', '5-Cornell', '6-Earlham', '7-Vermont']\n",
      "\n",
      "Standings for 1988:\n",
      "['1-California-Santa Barbara', '2-California-Davis', '3T-Humboldt State', '3T-Oregon', '5T-Carleton College', '5T-Massachusetts', '7T-Cornell', '7T-Wisconsin', '9T-Florida', '9T-Kansas']\n",
      "\n",
      "Standings for 1989:\n",
      "['1-California-Davis', '2-Michigan', '3T-California- Santa Barbara', '3T-Carleton College', '?-Cornell', '?-North Carolina-Wilmington', '?-Oregon', '?-Pennsylvania', '?-SUNY-Binghampton', '?-Towson']\n",
      "\n",
      "Standings for 1990:\n",
      "['1-California-Santa Barbara', '2-Michigan', '3-Cornell', '4-Carleton College', '5-California-Davis', '6-Carnegie Mellon', '7T-Columbia', '7T-Kansas', '9T-Pennsylvania', '9T-Wesleyan']\n",
      "\n",
      "Standings for 1991:\n",
      "['1-California- Santa Barbara', '2-California', '3T-Carleton College', '3T-Cornell', '5T-North Carolina-Wilmington', '5T-Virginia', '7T-Columbia', '7T-Kansas', '9T-Carnegie Mellon', '9T-Tufts']\n",
      "\n",
      "Standings for 1992:\n",
      "['1-North Carolina-Wilmington', '2-Oregon', '3T-California', '3T-Columbia', '5T-Carleton College', '5T-Cornell', '5T-Pennsylvania', '5T-Kansas', '9T-Brown', '9T-Georgia Tech']\n",
      "\n",
      "Standings for 1993:\n",
      "['1-California', '2-North Carolina-Wilmington', '3T-Carleton College', '3T-Humboldt State', '5T-Columbia', '5T-Cornell', '5T-Indiana', '5T-Pennsylvania', '9T-Kansas', '9T-Williams']\n",
      "\n",
      "Standings for 1994:\n",
      "['1-California-Santa Cruz', '2-California-Santa Barbara', '3T-Indiana', '3T-North Carolina-Wilmington', '5T-Carleton College', '5T-Columbia', '5T-Cornell', '5T-Kansas', '9T-East Carolina', '9T-Tufts']\n",
      "\n",
      "Standings for 1995:\n",
      "['1- California- Santa Cruz', '2-Stanford', '3T-Colorado', '3T-North Carolina-Wilmington', '5T-Columbia', '5T-Pennsylvania', '7T-Indiana', '7T-Yale', '9T-Carleton College', '9T-Williams']\n",
      "\n",
      "Standings for 1996:\n",
      "['1-North Carolina-Wilmington', '2-Stanford', '3T-Calif0rnia', '3T-Carleton College', '5T-Colorado', '5T-Cornell', '5T-Indiana', '5T-Yale', '9T-Florida State', '9T-Pennsylvania']\n",
      "\n",
      "Standings for 1997:\n",
      "['1- Stanford', '2-British Columbia', '3T-Carleton College', '3T-Rutgers', '5T-Brown', '5T-North Carolina-Wilmington', '5T-Oberlin', '5T-Yale', '9T-Georgia', '9T-Rice']\n",
      "\n",
      "Standings for 1998:\n",
      "['1-Stanford', '2-Carleton College', '3T-Oregon', '3T-Yale', '5T-Cornell', '5T-North Carolina-Wilmington', '7T-Indiana', '7T-Rutgers', '9T-Georgia', '9T-MIT', '11T-Rice', '11T-Wisconsin']\n",
      "\n",
      "Standings for 1999:\n",
      "['1- Stanford', '2-Carleton College', '3T-Brown', '3T-Georgia', '5T-British Columbia', '5T-California- San Diego', '7T- Swarthmore', '7T-Yale', '9T-Illinois', '9T-Princeton', '11T-Kansas', '11T-Minnesota']\n",
      "\n",
      "Standings for 2000:\n",
      "['1-Carleton College', '2-North Carolina-Wilmington', '3T-California- Davis', '3T-Georgia', '5T-Brown', '5T-California-San Diego', '5T-Colorado', '5T-Tufts', '9-Swarthmore', '10-Smith', '11-Minnesota', '12-Rice', '13-Oregon', '14-Illinois', '15T-Bucknell', '15T-Notre Dame']\n",
      "\n",
      "Standings for 2001:\n",
      "['1-Georgia', '2-Stanford', '3T-California- San Diego', '3T-North Carolina- Wilmington', '5T-British Columbia', '5T-Brown', '5T-Carleton College', '5T-Tufts', '9- Colorado', '10-Northwestern', '11-Bucknell', '12-Swarthmore', '13-Illinois', '14-MIT', '15-Wisconsin', '16-Washington']\n",
      "\n",
      "Standings for 2002:\n",
      "['1-California-San Diego', '2-Stanford', '3T-Colorado', '3T-MIT', '5T-Bucknell', '5T-Carleton College', '5T-North Carolina', '5T-Oregon', '9T-Brown', '9T-Northwestern', '11T-Penn State', '11T-Virginia', '13T-Georgia', '13T-Indiana', '15T-Texas', '15T- Yale']\n",
      "\n",
      "Standings for 2003:\n",
      "['1-Stanford', '2-MIT', '3T-Brown', '3T-Colorado', '5T-California', '5T-California-San Diego', '5T-Penn State', '5T-Texas', '9T-Iowa', '9T-Wisconsin', '11T-Delaware', '11T-Duke', '13-Michigan', '14T-Arizona', '14T-Georgia', '14T-Notre Dame']\n",
      "\n",
      "Standings for 2004:\n",
      "['1- California-Davis', '2-Carleton College', '3T-California-San Diego', '3T-Stanford', '5T-Brown', '5T-California', '5T-Texas', '5T-MIT', '9T-Dartmouth', '9T-Iowa', '11T-Claremont', '11T-Illinois', '13T-Penn State', '15T-North Carolina State', '15T-Rutgers']\n",
      "\n",
      "Standings for 2005:\n",
      "['1-Stanford', '2-Washington', '3T-Colorado', '3T-Texas', '5T-Brown', '5T-California', '5T-Iowa', '5T-North Carolina State', '9T-Cornell', '9T-MIT', '11T-Dartmouth', '11T-Northwestern', '13-Texas A&M', '14T-Carleton College', '14T-Purdue', '14T-Rutgers']\n",
      "\n",
      "Standings for 2006:\n",
      "['1-Stanford', '2-UCLA', '3T-Colorado', '3T-Wisconsin', '5T-British Columbia', '5T-California-Davis', '5T-Dartmouth', '5T-Florida', '9T-Georgia', '9T-Michigan', '11T-Emory', '11T-Tufts', '13T-Swarthmore', '13T-Texas', '15T-Carleton College', '15T-Delaware']\n",
      "\n",
      "Standings for 2007:\n",
      "['1-Stanford', '2-California-Santa Barbara', '3T-British Columbia', '3T-UCLA', '5T- California', '5T-Carleton College', '5T-Northwestern', '5T-Wisconsin', '9T-California-San Diego', '9T-NYU', '11T-Delaware', '11T-Tufts', '13T-Florida', '13T-Truman State', '15T-Dartmouth', '15T-Emory']\n",
      "\n",
      "Standings for 2008:\n",
      "['1-British Columbia', '2-California-Santa Barbara', '3T-UCLA', '3T-Washington', '5T-Carleton College', '5T-Michigan', '5T-Ottawa', '5T-Wisconsin', '9T-Northeastern', '9T-Texas', '11T-Maryland', '11T-Michigan State', '13T-Wake Forest', '13T-Oregon', '15T-MIT', '15T-North Carolina']\n",
      "\n",
      "Standings for 2009:\n",
      "['1-California-Santa Barbara', '2-Washington', '3T-Oregon', '3T-Stanford', '5T-Ottawa', '5T-Pennsylvania', '5T-UCLA', '5T-Wisconsin', '9T-Carleton College', '9T-Michigan', '11T-North Carolina', '11T-North Carolina-Wilmington', '13T-Dartmouth', '13T-Saint Louis', '15T-Colorado', '15T-Iowa State', '17T-Northeastern', '17T-Washington University', '19T-Illinois', '19T-Southern California']\n",
      "\n",
      "Standings for 2010:\n",
      "['1- Oregon', '2- California- Santa Barbara', '3T-Colorado', '3T-Wisconsin', '5T-California', '5T-North Carolina- Wilmington', '5T-Southern California', '5T-UCLA', '9T-PIttsburgh', '9T-Washington', '11T-Carleton College', '11T-Michigan', '13T-Stanford', '13T- North Carolina', '15T-Maryland', '15T-Washington University', '17T- Northwestern', '17T- Texas', '19T- Harvard', '19T- Middlebury']\n",
      "\n",
      "Standings for 2011:\n",
      "['1-California-Santa Barbara', '2-Michigan', '3T-Oregon', '3T-Stanford', '5T-Colorado College', '5T-Iowa', '5T-North Carolina', '5T-North Carolina- Wilmington', '9- Washington', '10- Iowa State', '11-California', '12-Carleton College', '13T-Northwestern', '13T-Ottawa', '15T-Florida', '15T-Tufts', '17T-Ohio State', '17T- Washington University', '19T-British Columbia', '19T- Virginia']\n",
      "\n",
      "Standings for 2012:\n",
      "['1-Washington', '2-Oregon', '3T-Michigan', '3T-Tufts', '5T-Iowa', '5T-North Carolina', '5T-Ohio State', '5T-Texas', '9- California', '10-Iowa State', '11-British Columbia', '12-UCLA', '13T-Florida', '13T-Stanford', '15T-Sonoma State', '15T-Wisconsin', '17T-Humboldt State', '17T-Virginia', '19T-Delaware', '19T-Ottawa']\n",
      "\n",
      "Standings for 2013:\n",
      "['1- Oregon', '2- Carleton College', '3T- Iowa', '3T- Ohio State', '5T- British Columbia', '5T- Tufts', '5T- Virginia', '5T-Washington', '9T- Iowa State', '9T- Minnesota', '9T- Northwestern', '9T- Wisconsin', '13T- California- Santa Barbara', '13T- Ottawa', '13T- Stanford', '13T- Whitman', '17T- Central Florida', '17T- Georgia', '17T- Northeastern', '17T- Texas']\n",
      "\n",
      "Standings for 2014:\n",
      "['1- Ohio State', '2- Oregon', '3T- Central Florida', '3T- Washington', '5T- British Columbia', '5T- Carleton College', '5T- Michigan', '5T- Virginia', '9T-California- Santa Barbara', '9T- Colorado College', '9T- Tufts', '9T- UCLA', '13T- Colorado', '13T- Kansas', '13T- Stanford', '13T- Victoria', '17T- Cornell', '17T- Northeastern', '17T- Western Washington', '17T- Whitman']\n",
      "\n",
      "Standings for 2015:\n",
      "['1- Oregon', '2.- Stanford', '3T- British Columbia', '3T- Carleton College', '5T- Colorado', '5T- Dartmouth', '5T- Virginia', '5T- Whitman', '9T- Florida State', '9T- Ohio State', '9T- Texas', '9T- Victoria', '13T- Central Florida', '13T- Princeton', '13T- UCLA', '13T- Washington', '17T- Kansas', '17T- Middlebury', '17T- Notre Dame', '17T- Pittsburgh']\n",
      "\n",
      "Standings for 2016:\n",
      "['1- Stanford', '2- Whitman', 'T3- Oregon', 'T3- Virginia', 'T5- British Columbia', 'T5- Colorado', 'T5- Dartmouth', 'T5- UCLA', 'T9-Michigan', 'T9- Texas', 'T9- Washington', 'T9- Wisconsin', 'T13- California', 'T13- Western Washington**', 'T13- Colorado College', 'T13- Pittsburgh', 'T17- Central Florida', 'T17- Ohio State', 'T17- Ottawa', 'T17- Southern California']\n",
      "\n",
      "Standings for 2017:\n",
      "['1- Dartmouth', '2-Texas', 'T3- British Columbia', 'T3- Colorado', 'T5- Oregon', 'T5- Stanford', 'T9-California', 'T9-Carleton College', 'T9-Michigan', 'T9-Notre Dame', 'T13-California- San Diego', 'T13- Delaware', 'T13-North Carolina', 'T13-Ohio State', 'T17- Connecticut', 'T17- Florida', 'T17- Pittsburgh', 'T17- Tufts']\n",
      "\n",
      "Standings for 2018:\n",
      "['1 – Dartmouth', '2 – Colorado', 'T3 – Pittsburgh', 'T3 – Stanford', 'T5 – British Columbia', 'T5 – North Carolina', 'T5 – Oregon', 'T5 – Texas', 'T9 – California-San Diego', 'T9 – Michigan', 'T9 – North Carolina State', 'T9 – Tufts', 'T13 – Carleton College', 'T13 – Ohio State', 'T13 – West Chester', 'T13 – Western Washington', 'T17 – California-Santa Barbara', 'T17 – Cornell', 'T17 – Florida', 'T17 – Whitman']\n",
      "\n",
      "Standings for 2019:\n",
      "['1 – California-San Diego', '2 – Dartmouth', 'T3 – North Carolina', 'T3 – Ohio State', 'T5 – Carleton College-Syzygy', 'T5 – Western Washington', 'T5 – California-Santa Barbara', 'T5 – Wisconsin', 'T9 – Georgia', 'T9 – Colorado', 'T9 – Minnesota', 'T9 – Oregon', 'T13 – Texas', 'T13 – UCLA', 'T13 – Washington', 'T13 – Northwestern', 'T17 – Pittsburgh', 'T17 – Northeastern', 'T17 – Tufts', 'T17 – Cornell']\n",
      "\n",
      "Standings for 2021:\n",
      "['1 – North Carolina', '2 – Washington', 'T3 – Carleton-Syzygy', 'T3 – California-Santa Barbara', 'T5 – Virginia', 'T5 – California-San Diego', 'T5 – Pittsburgh', 'T5 – California-Davis', 'T9 – Western Washington', 'T9 – Colorado', 'T11 – Texas', 'T11 – Chicago', 'T13 – Vermont', 'T13 – Georgia', 'T15 – Florida State', 'T15 – Ohio', 'T17 – Pennsylvania', 'T17 – SUNY-Binghamton', 'T19 – Michigan', 'T19 – Boston University']\n",
      "\n",
      "Standings for 2022:\n",
      "['1 – North Carolina', '2 – Colorado', 'T3 – Carleton College', 'T3 – California-Santa Barbara', 'T5 – British Columbia', 'T5 – Tufts', 'T5 – Washington', 'T5 –Vermont', 'T9 – California-Davis', 'T9 – California-San Diego', 'T9 – Florida State', 'T9 –Stanford', 'T13 – Georgia', 'T13 – Pittsburgh', 'T15 –William & Mary', 'T15 – Virginia', 'T17 – Purdue', 'T17 – Northeastern', 'T19 – SUNY-Binghamton', 'T19 – Colorado State']\n",
      "\n",
      "Standings for 2023:\n",
      "['1 – North Carolina', '2 – Colorado', 'T3 – British Columbia', 'T3 – Vermont', 'T5 – Carleton College', 'T5 – Stanford', 'T5 – Tufts', 'T5 – Washington', 'T9 – California-Santa Barbara', 'T9 – Colorado State', 'T9 – Northeastern', 'T9 – Oregon', 'T13 – UCLA', 'T13 – Virginia', 'T15 – Chicago', 'T15 – Victoria', 'T17 – Georgia', 'T17 – SUNY-Binghamton', 'T19 – Carnegie Mellon', 'T19 – Texas-Dallas']\n"
     ]
    }
   ],
   "source": [
    "for url, standings in all_standings.items():\n",
    "    print(f\"\\nStandings for {url}:\")\n",
    "    print(standings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 standings after fix:\n",
      "1 – North Carolina\n",
      "2 – Colorado\n",
      "T3 – Carleton College\n",
      "T3 – California-Santa Barbara\n",
      "T5 – British Columbia\n",
      "T5 – Tufts\n",
      "T5 – Washington\n",
      "T5 – Vermont\n",
      "T9 – California-Davis\n",
      "T9 – California-San Diego\n",
      "T9 – Florida State\n",
      "T9 – Stanford\n",
      "T13 – Georgia\n",
      "T13 – Pittsburgh\n",
      "T15 – William & Mary\n",
      "T15 – Virginia\n",
      "T17 – Purdue\n",
      "T17 – Northeastern\n",
      "T19 – SUNY-Binghamton\n",
      "T19 – Colorado State\n"
     ]
    }
   ],
   "source": [
    "# Fix entries in 2022 standings\n",
    "if 2022 in all_standings:\n",
    "    all_standings[2022] = [\n",
    "        entry.replace('T5 –Vermont', 'T5 – Vermont')\n",
    "        .replace('T9 –Stanford', 'T9 – Stanford')\n",
    "        .replace('T15 –William & Mary', 'T15 – William & Mary')\n",
    "        for entry in all_standings[2022]\n",
    "    ]\n",
    "\n",
    "# Verify the fix\n",
    "print(\"2022 standings after fix:\")\n",
    "for entry in all_standings[2022]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store our data\n",
    "data = []\n",
    "\n",
    "# Iterate through the standings dictionary\n",
    "for year, standings in all_standings.items():\n",
    "    if isinstance(standings, list):  # Only process if we have actual standings data\n",
    "        for i, entry in enumerate(standings, 1):\n",
    "            if year > 2017:\n",
    "                # Try both types of dashes for newer years\n",
    "                if ' – ' in entry:  # en dash\n",
    "                    parts = entry.split(' – ', 1)\n",
    "                elif ' - ' in entry:  # regular hyphen\n",
    "                    parts = entry.split(' - ', 1)\n",
    "                else:\n",
    "                    parts = entry.split('-', 1)\n",
    "            else:\n",
    "                # Pre-2016 format\n",
    "                parts = entry.split('-', 1)\n",
    "            \n",
    "            if len(parts) == 2:\n",
    "                web_finish = parts[0].strip()\n",
    "                team = parts[1].strip()\n",
    "                \n",
    "                data.append({\n",
    "                    'URL': urls[year],\n",
    "                    'Year': year,\n",
    "                    'Team': team,\n",
    "                    'Web_Finish': web_finish,\n",
    "                    'List_Finish': i\n",
    "                })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Year</th>\n",
       "      <th>Team</th>\n",
       "      <th>Web_Finish</th>\n",
       "      <th>List_Finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>1987</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>1987</td>\n",
       "      <td>California- Davis</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>1987</td>\n",
       "      <td>Humboldt State</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>1987</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>1987</td>\n",
       "      <td>Cornell</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>T15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>T17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>2023</td>\n",
       "      <td>SUNY-Binghamton</td>\n",
       "      <td>T17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Carnegie Mellon</td>\n",
       "      <td>T19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Texas-Dallas</td>\n",
       "      <td>T19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL  Year  \\\n",
       "0    https://collegechampionships.usaultimate.org/d...  1987   \n",
       "1    https://collegechampionships.usaultimate.org/d...  1987   \n",
       "2    https://collegechampionships.usaultimate.org/d...  1987   \n",
       "3    https://collegechampionships.usaultimate.org/d...  1987   \n",
       "4    https://collegechampionships.usaultimate.org/d...  1987   \n",
       "..                                                 ...   ...   \n",
       "547  https://collegechampionships.usaultimate.org/d...  2023   \n",
       "548  https://collegechampionships.usaultimate.org/d...  2023   \n",
       "549  https://collegechampionships.usaultimate.org/d...  2023   \n",
       "550  https://collegechampionships.usaultimate.org/d...  2023   \n",
       "551  https://collegechampionships.usaultimate.org/d...  2023   \n",
       "\n",
       "                  Team Web_Finish  List_Finish  \n",
       "0               Kansas          1            1  \n",
       "1    California- Davis          2            2  \n",
       "2       Humboldt State          3            3  \n",
       "3        Massachusetts          4            4  \n",
       "4              Cornell          5            5  \n",
       "..                 ...        ...          ...  \n",
       "547           Victoria        T15           16  \n",
       "548            Georgia        T17           17  \n",
       "549    SUNY-Binghamton        T17           18  \n",
       "550    Carnegie Mellon        T19           19  \n",
       "551       Texas-Dallas        T19           20  \n",
       "\n",
       "[552 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export to CSV\n",
    "# df.to_csv('college-womens-raw-rankings.csv', index=False)\n",
    "# print(\"Data exported to 'college-womens-raw-rankings.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All raw teams in alphabetical order:\n",
      "Arizona\n",
      "Boston University\n",
      "British Columbia\n",
      "Brown\n",
      "Bucknell\n",
      "Calif0rnia\n",
      "California\n",
      "California- Davis\n",
      "California- San Diego\n",
      "California- Santa Barbara\n",
      "California- Santa Cruz\n",
      "California-Davis\n",
      "California-San Diego\n",
      "California-Santa Barbara\n",
      "California-Santa Cruz\n",
      "Carleton College\n",
      "Carleton College-Syzygy\n",
      "Carleton-Syzygy\n",
      "Carnegie Mellon\n",
      "Central Florida\n",
      "Chicago\n",
      "Claremont\n",
      "Colorado\n",
      "Colorado College\n",
      "Colorado State\n",
      "Columbia\n",
      "Connecticut\n",
      "Cornell\n",
      "Dartmouth\n",
      "Delaware\n",
      "Duke\n",
      "Earlham\n",
      "East Carolina\n",
      "Emory\n",
      "Florida\n",
      "Florida State\n",
      "Georgia\n",
      "Georgia Tech\n",
      "Harvard\n",
      "Humboldt State\n",
      "Illinois\n",
      "Indiana\n",
      "Iowa\n",
      "Iowa State\n",
      "Kansas\n",
      "MIT\n",
      "Maryland\n",
      "Massachusetts\n",
      "Michigan\n",
      "Michigan State\n",
      "Middlebury\n",
      "Minnesota\n",
      "NYU\n",
      "North Carolina\n",
      "North Carolina State\n",
      "North Carolina- Wilmington\n",
      "North Carolina-Wilmington\n",
      "Northeastern\n",
      "Northwestern\n",
      "Notre Dame\n",
      "Oberlin\n",
      "Ohio\n",
      "Ohio State\n",
      "Oregon\n",
      "Ottawa\n",
      "PIttsburgh\n",
      "Penn State\n",
      "Pennsylvania\n",
      "Pittsburgh\n",
      "Princeton\n",
      "Purdue\n",
      "Rice\n",
      "Rutgers\n",
      "SUNY-Binghampton\n",
      "SUNY-Binghamton\n",
      "Saint Louis\n",
      "Smith\n",
      "Sonoma State\n",
      "Southern California\n",
      "Stanford\n",
      "Swarthmore\n",
      "Texas\n",
      "Texas A&M\n",
      "Texas-Dallas\n",
      "Towson\n",
      "Truman State\n",
      "Tufts\n",
      "UCLA\n",
      "Vermont\n",
      "Victoria\n",
      "Virginia\n",
      "Wake Forest\n",
      "Washington\n",
      "Washington University\n",
      "Wesleyan\n",
      "West Chester\n",
      "Western Washington\n",
      "Western Washington**\n",
      "Whitman\n",
      "William & Mary\n",
      "Williams\n",
      "Wisconsin\n",
      "Yale\n"
     ]
    }
   ],
   "source": [
    "# Get unique team names and sort alphabetically\n",
    "unique_teams_raw = sorted(df['Team'].unique())\n",
    "\n",
    "# Print the teams\n",
    "print(\"All raw teams in alphabetical order:\")\n",
    "for team in unique_teams_raw:\n",
    "    print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_team_name(team):\n",
    "    # Apply the cleaning function to create new column\n",
    "    team_fixes = {\n",
    "        'Calif0rnia': 'California',\n",
    "        'PIttsburgh': 'Pittsburgh',\n",
    "        'Western Washington**': 'Western Washington',\n",
    "        'SUNY-Binghampton': 'SUNY-Binghamton',\n",
    "        'California- Davis': 'UC Davis',\n",
    "        'California-Davis': 'UC Davis',\n",
    "        'California- San Diego': 'UC San Diego',\n",
    "        'California-San Diego': 'UC San Diego',\n",
    "        'California- Santa Barbara': 'UC Santa Barbara',\n",
    "        'California-Santa Barbara': 'UC Santa Barbara',\n",
    "        'California- Santa Cruz': 'UC Santa Cruz',\n",
    "        'California-Santa Cruz': 'UC Santa Cruz',\n",
    "        'Carleton College-Syzygy': 'Carleton',\n",
    "        'Carleton-Syzygy': 'Carleton',\n",
    "        'Carleton College': 'Carleton'\n",
    "    }\n",
    "    \n",
    "    return team_fixes.get(team, team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All teams after cleaning (alphabetically):\n",
      "Arizona\n",
      "Boston University\n",
      "British Columbia\n",
      "Brown\n",
      "Bucknell\n",
      "California\n",
      "Carleton\n",
      "Carnegie Mellon\n",
      "Central Florida\n",
      "Chicago\n",
      "Claremont\n",
      "Colorado\n",
      "Colorado College\n",
      "Colorado State\n",
      "Columbia\n",
      "Connecticut\n",
      "Cornell\n",
      "Dartmouth\n",
      "Delaware\n",
      "Duke\n",
      "Earlham\n",
      "East Carolina\n",
      "Emory\n",
      "Florida\n",
      "Florida State\n",
      "Georgia\n",
      "Georgia Tech\n",
      "Harvard\n",
      "Humboldt State\n",
      "Illinois\n",
      "Indiana\n",
      "Iowa\n",
      "Iowa State\n",
      "Kansas\n",
      "MIT\n",
      "Maryland\n",
      "Massachusetts\n",
      "Michigan\n",
      "Michigan State\n",
      "Middlebury\n",
      "Minnesota\n",
      "NYU\n",
      "North Carolina\n",
      "North Carolina State\n",
      "North Carolina- Wilmington\n",
      "North Carolina-Wilmington\n",
      "Northeastern\n",
      "Northwestern\n",
      "Notre Dame\n",
      "Oberlin\n",
      "Ohio\n",
      "Ohio State\n",
      "Oregon\n",
      "Ottawa\n",
      "Penn State\n",
      "Pennsylvania\n",
      "Pittsburgh\n",
      "Princeton\n",
      "Purdue\n",
      "Rice\n",
      "Rutgers\n",
      "SUNY-Binghamton\n",
      "Saint Louis\n",
      "Smith\n",
      "Sonoma State\n",
      "Southern California\n",
      "Stanford\n",
      "Swarthmore\n",
      "Texas\n",
      "Texas A&M\n",
      "Texas-Dallas\n",
      "Towson\n",
      "Truman State\n",
      "Tufts\n",
      "UC Davis\n",
      "UC San Diego\n",
      "UC Santa Barbara\n",
      "UC Santa Cruz\n",
      "UCLA\n",
      "Vermont\n",
      "Victoria\n",
      "Virginia\n",
      "Wake Forest\n",
      "Washington\n",
      "Washington University\n",
      "Wesleyan\n",
      "West Chester\n",
      "Western Washington\n",
      "Whitman\n",
      "William & Mary\n",
      "Williams\n",
      "Wisconsin\n",
      "Yale\n"
     ]
    }
   ],
   "source": [
    "# Apply the cleaning function to create new column\n",
    "df['Team_Clean'] = df['Team'].apply(clean_team_name)\n",
    "\n",
    "# Print unique teams after cleaning to verify changes\n",
    "print(\"All teams after cleaning (alphabetically):\")\n",
    "for team in sorted(df['Team_Clean'].unique()):\n",
    "    print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Year</th>\n",
       "      <th>Team</th>\n",
       "      <th>Web_Finish</th>\n",
       "      <th>List_Finish</th>\n",
       "      <th>Team_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>1987</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Kansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>1987</td>\n",
       "      <td>California- Davis</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>UC Davis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>1987</td>\n",
       "      <td>Humboldt State</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Humboldt State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>1987</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>1987</td>\n",
       "      <td>Cornell</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Cornell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>T15</td>\n",
       "      <td>16</td>\n",
       "      <td>Victoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>T17</td>\n",
       "      <td>17</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>2023</td>\n",
       "      <td>SUNY-Binghamton</td>\n",
       "      <td>T17</td>\n",
       "      <td>18</td>\n",
       "      <td>SUNY-Binghamton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Carnegie Mellon</td>\n",
       "      <td>T19</td>\n",
       "      <td>19</td>\n",
       "      <td>Carnegie Mellon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>https://collegechampionships.usaultimate.org/d...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Texas-Dallas</td>\n",
       "      <td>T19</td>\n",
       "      <td>20</td>\n",
       "      <td>Texas-Dallas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL  Year  \\\n",
       "0    https://collegechampionships.usaultimate.org/d...  1987   \n",
       "1    https://collegechampionships.usaultimate.org/d...  1987   \n",
       "2    https://collegechampionships.usaultimate.org/d...  1987   \n",
       "3    https://collegechampionships.usaultimate.org/d...  1987   \n",
       "4    https://collegechampionships.usaultimate.org/d...  1987   \n",
       "..                                                 ...   ...   \n",
       "547  https://collegechampionships.usaultimate.org/d...  2023   \n",
       "548  https://collegechampionships.usaultimate.org/d...  2023   \n",
       "549  https://collegechampionships.usaultimate.org/d...  2023   \n",
       "550  https://collegechampionships.usaultimate.org/d...  2023   \n",
       "551  https://collegechampionships.usaultimate.org/d...  2023   \n",
       "\n",
       "                  Team Web_Finish  List_Finish       Team_Clean  \n",
       "0               Kansas          1            1           Kansas  \n",
       "1    California- Davis          2            2         UC Davis  \n",
       "2       Humboldt State          3            3   Humboldt State  \n",
       "3        Massachusetts          4            4    Massachusetts  \n",
       "4              Cornell          5            5          Cornell  \n",
       "..                 ...        ...          ...              ...  \n",
       "547           Victoria        T15           16         Victoria  \n",
       "548            Georgia        T17           17          Georgia  \n",
       "549    SUNY-Binghamton        T17           18  SUNY-Binghamton  \n",
       "550    Carnegie Mellon        T19           19  Carnegie Mellon  \n",
       "551       Texas-Dallas        T19           20     Texas-Dallas  \n",
       "\n",
       "[552 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create new dataframe without URL and Team columns\n",
    "# df_clean = df.drop(['URL', 'Team', 'Web_Finish'], axis=1)\n",
    "\n",
    "# # Rename Team_Clean to Team for clarity\n",
    "# df_clean = df_clean.rename(columns={'Team_Clean': 'Team', 'List_Finish': 'Rank'})\n",
    "\n",
    "# # Create Time column accounting for missing 2020 season\n",
    "# df_clean['Time'] = df_clean.apply(lambda row: \n",
    "#     row['Year'] - 1983 if row['Year'] < 2020 \n",
    "#     else row['Year'] - 1984, axis=1)\n",
    "\n",
    "# # Reorder columns\n",
    "# df_clean = df_clean[['Team', 'Time', 'Rank', 'Year']]\n",
    "\n",
    "# # Verify the first few rows to check the mapping\n",
    "# df_clean\n",
    "\n",
    "# # Export to CSV\n",
    "# df_clean.to_csv('ultimate_standings_clean.csv', index=False)\n",
    "# print(\"Data exported to 'ultimate_standings_clean.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_rank_format(df, column_name):\n",
    "    def convert_format(rank):\n",
    "        # If it's already in T# format, keep it\n",
    "        if isinstance(rank, str) and rank.startswith('T'):\n",
    "            return rank\n",
    "        \n",
    "        # If it ends with T, convert to T# format\n",
    "        if isinstance(rank, str) and rank.endswith('T'):\n",
    "            number = rank[:-1]  # Remove the T\n",
    "            return f'T{number}'\n",
    "        \n",
    "        return rank  # Return unchanged if no T\n",
    "\n",
    "    # Apply the conversion to the specified column\n",
    "    df[column_name] = df[column_name].apply(convert_format)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to 'college-womens-rankings.csv'\n"
     ]
    }
   ],
   "source": [
    "# Create new dataframe without URL and Team columns\n",
    "df_T = df.drop(['URL', 'Team'], axis=1)\n",
    "\n",
    "# Apply the conversion to the specified column\n",
    "df = transform_rank_format(df_T, 'Web_Finish')\n",
    "\n",
    "# Rename Team_Clean to Team for clarity\n",
    "df_T = df_T.rename(columns={'Team_Clean': 'Team', 'List_Finish': 'Rank', 'Web_Finish': 'T_Rank'})\n",
    "\n",
    "# Reorder columns\n",
    "df_T = df_T[['Team', 'Year', 'Rank', 'T_Rank']]\n",
    "\n",
    "# Manually change a rank value for UNC Wilmington in 2021\n",
    "df_T.loc[(df_T['Team'] == 'UNC Wilmington') & (df_T['Year'] == 2021), 'T_Rank'] = 'T9'\n",
    "\n",
    "# Verify the first few rows to check the mapping\n",
    "df_T\n",
    "\n",
    "# Export to CSV\n",
    "df_T.to_csv('college-womens-rankings.csv', index=False)\n",
    "print(\"Data exported to 'college-womens-rankings.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the CSV\n",
    "# df_with_less_columns_for_tableau = pd.read_csv('ultimate_standings_clean.csv')\n",
    "\n",
    "# # Group by year and check rank sequences\n",
    "# found_issues = False\n",
    "# for year in sorted(df_with_less_columns_for_tableau['Year'].unique()):\n",
    "#     year_data = df_with_less_columns_for_tableau[df_with_less_columns_for_tableau['Year'] == year].sort_values('Rank')\n",
    "#     ranks = year_data['Rank'].tolist()\n",
    "#     expected_ranks = list(range(1, len(ranks) + 1))\n",
    "    \n",
    "#     if ranks != expected_ranks:\n",
    "#         found_issues = True\n",
    "#         print(f\"\\nYear {year} has non-sequential ranks:\")\n",
    "#         print(\"Expected:\", expected_ranks)\n",
    "#         print(\"Actual:\", ranks)\n",
    "#         print(\"\\nFull data for this year:\")\n",
    "#         print(year_data[['Team', 'Rank']].to_string())\n",
    "\n",
    "# if not found_issues:\n",
    "#     print(\"All years have sequential ranks without gaps! ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Web_Finish</th>\n",
       "      <th>List_Finish</th>\n",
       "      <th>Team_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Kansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>UC Davis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Humboldt State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Cornell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2023</td>\n",
       "      <td>T15</td>\n",
       "      <td>16</td>\n",
       "      <td>Victoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2023</td>\n",
       "      <td>T17</td>\n",
       "      <td>17</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>2023</td>\n",
       "      <td>T17</td>\n",
       "      <td>18</td>\n",
       "      <td>SUNY-Binghamton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2023</td>\n",
       "      <td>T19</td>\n",
       "      <td>19</td>\n",
       "      <td>Carnegie Mellon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>2023</td>\n",
       "      <td>T19</td>\n",
       "      <td>20</td>\n",
       "      <td>Texas-Dallas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year Web_Finish  List_Finish       Team_Clean\n",
       "0    1987          1            1           Kansas\n",
       "1    1987          2            2         UC Davis\n",
       "2    1987          3            3   Humboldt State\n",
       "3    1987          4            4    Massachusetts\n",
       "4    1987          5            5          Cornell\n",
       "..    ...        ...          ...              ...\n",
       "547  2023        T15           16         Victoria\n",
       "548  2023        T17           17          Georgia\n",
       "549  2023        T17           18  SUNY-Binghamton\n",
       "550  2023        T19           19  Carnegie Mellon\n",
       "551  2023        T19           20     Texas-Dallas\n",
       "\n",
       "[552 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a big df with logo urls\n",
    "\n",
    "# # Read in the csv with the team names and urls\n",
    "# team_logos_df = pd.read_csv('team_logos.csv')\n",
    "\n",
    "# team_logos_df\n",
    "\n",
    "# # Remove duplicates from team_logos_df before merging\n",
    "# team_logos_df_unique = team_logos_df.drop_duplicates('team_name')\n",
    "\n",
    "# team_logos_df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge the two dfs on the team name\n",
    "\n",
    "# # This will:\n",
    "# # Match rows where df['Team_Clean'] equals team_logos_df['team_name']\n",
    "# # Keep all rows from df (due to left join)\n",
    "# # Add all columns from team_logos_df\n",
    "# # Optionally remove the duplicate team name column\n",
    "\n",
    "# # Merge using left_on and right_on to specify the different column names\n",
    "# df_merged = pd.merge(\n",
    "#     df, \n",
    "#     team_logos_df_unique, \n",
    "#     left_on='Team_Clean',\n",
    "#     right_on='team_nam\n",
    "#     how='left'\n",
    "# )\n",
    "\n",
    "# df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the merged DataFrame to a CSV file\n",
    "# df_merged.to_csv('ultimate_standings_merged.csv', index=False)\n",
    "# print(\"Data exported to 'ultimate_standings_merged.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add missing logos manually\n",
    "\n",
    "# teams_with_missing_logos = [\n",
    "#     #'Arizona',\n",
    "#     #'Boston College',\n",
    "#     #'Carnegie Mellon',\n",
    "#     #'Case Western Reserve',\n",
    "#     #'Chabot Community College',\n",
    "#     'Colorado College',\n",
    "#     'Cornell',\n",
    "#     'Dartmouth',\n",
    "#     'Delaware',\n",
    "#     'East Carolina',\n",
    "#     'Eastern Michigan',\n",
    "#     'Florida State',\n",
    "#     'George Washington',\n",
    "#     'Glassboro',\n",
    "#     'Indiana',\n",
    "#     'Iowa',\n",
    "#     'Kansas',\n",
    "#     'Las Positas College',\n",
    "#     'Luther',\n",
    "#     'Michigan State',\n",
    "#     'Middlebury',\n",
    "#     'Minnesota-Duluth',\n",
    "#     'North Texas',\n",
    "#     'Notre Dame',\n",
    "#     'Oberlin',\n",
    "#     'Ohio',\n",
    "#     'Penn',\n",
    "#     'Princeton',\n",
    "#     \"Queen's\",\n",
    "#     'Rice',\n",
    "#     'Rutgers',\n",
    "#     'Saint Louis',\n",
    "#     'Salisbury',\n",
    "#     'Suny-Albany',\n",
    "#     'Suny-Binghampton',\n",
    "#     'Suny-Purchase',\n",
    "#     'Sw Missouri State',\n",
    "#     'Swarthmore',\n",
    "#     'Syracuse',\n",
    "#     'Texas State',\n",
    "#     'UC Davis',\n",
    "#     'Utah',\n",
    "#     'Virginia',\n",
    "#     'Wesleyan',\n",
    "#     'Whitman',\n",
    "#     'Williams',\n",
    "#     'Wilmington',\n",
    "#     'Winona State',\n",
    "#     'Yale'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get unique teams and sort them\n",
    "# unique_teams = sorted(df_merged['Team_Clean'].unique())\n",
    "\n",
    "\n",
    "# # Print them to verify\n",
    "# for team in unique_teams:\n",
    "#     print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding team results manually, for 2024\n",
    "\n",
    "# Read in the existing CSV\n",
    "df_T = pd.read_csv('college-womens-rankings.csv')\n",
    "\n",
    "# Remove any existing 2024 entries\n",
    "df_T = df_T[df_T['Year'] != 2024]\n",
    "\n",
    "# Create new data\n",
    "new_data = {\n",
    "    'Team': [\n",
    "        'North Carolina', 'Stanford', 'Colorado', 'Vermont', 'British Columbia',\n",
    "        'Carleton', 'Oregon', 'Tufts', 'UC San Diego', 'Michigan',\n",
    "        'Pennsylvania', 'UC Santa Barbara', 'Colorado State', 'Western Washington', 'SUNY Binghamton',\n",
    "        'Washington', 'UC Santa Cruz', 'Georgia', 'Utah', 'Victoria'\n",
    "    ],\n",
    "    'Year': [2024] * 20,\n",
    "    'Rank': list(range(1, 21)),\n",
    "    'T_Rank': [\n",
    "        '1', '2', 'T3', 'T3', 'T5', 'T5', 'T5', 'T5', 'T9', 'T9',\n",
    "        'T9', 'T9', 'T13', 'T13', 'T15', 'T15', 'T17', 'T17', 'T19', 'T19'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Append to existing DataFrame\n",
    "df_T = pd.concat([df_T, new_df], ignore_index=True)\n",
    "\n",
    "# Export to CSV\n",
    "df_T.to_csv('college-womens-rankings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
